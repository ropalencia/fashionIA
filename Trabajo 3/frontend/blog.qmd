---
title: "Recomendación de moda"
lang: es    
author:
  - name: Ronald Gabriel Palencia
    email: ropalencia@unal.edu.co
  - name: Junior Antonio Muños Henao
    email: jmunozhe@unal.edu.co
format:
  html:
    code-fold: true
jupyter: python3
echo: false
theme:
          light: flatly
          dark: darkly
toc: true
appendix-style: default
---

## portada 

```{python}
import numpy as np
import pandas as pd
import os
import re
import tensorflow as tf
from threading import Thread
import time
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
import pickle
import random
from tqdm import tqdm
import plotly.express as px
from plotly.offline import init_notebook_mode
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import Sequence, to_categorical
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer
from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201, Xception
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
init_notebook_mode(connected=True)
```



```{python}
#import zipfile
#import os

# Ruta del archivo ZIP en tu Google Drive
#zip_path = '/content/drive/Shareddrives/Redes 2024_1/Trabajo 3/archive.zip'

# Ruta donde deseas extraer los archivos
#extract_to = '/content/drive/Shareddrives/Redes 2024_1/Trabajo 3/extracted_files'

# Crear el directorio si no existe
#os.makedirs(extract_to, exist_ok=True)

# Descomprimir el archivo
#with zipfile.ZipFile(zip_path, 'r') as zip_ref:
#    zip_ref.extractall(extract_to)

#print(f'Archivos extraídos en: {extract_to}')
```


```{python}
styles_df = pd.read_csv("../Datos/styles.csv", on_bad_lines='skip')
```

```{python}
styles_df['filename'] = styles_df['id'].astype(str) + '.jpg'
```


```{python}
styles_df
```


```{python}
#Nota: primero cambiar images por pruebas y correr, luego volver a poner images y ahi si lee todas las direcciones, es raro al verdad

#Esto parece que no hace falta en qmd
image_files = os.listdir("../Datos/extracted_files/images")
```


```{python}
len(image_files)
```


```{python}
image_files[:5]
```


```{python}
import os

def check_image_path(filename):
    path = os.path.join("../Datos/extracted_files/images", filename)
    return path if os.path.exists(path) else None

styles_df['filename'] = styles_df['filename'].apply(check_image_path)
```

```{python}
styles_df
```


```{python}
# Filtrar filas donde la imagen no existe
styles_df = styles_df[styles_df['filename'].notnull()]
```


```{python}
styles_df
```

### Se verifica que todas las imagenes esten
```{python}
styles_df['file_found'] = styles_df['id'].apply(lambda x: f"{x}.jpg" in image_files)
```

```{python}
styles_df
```

```{python}
styles_df = styles_df[styles_df['file_found']].reset_index(drop=True)
```

```{python}
styles_df.shape[0]
```

## Base de datos final

```{python}
styles_df
```


```{python}
styles_df.isnull().sum()
```


```{python}
# Eliminamos las filas que contienen valores faltantes
styles_df_clean = styles_df.dropna()

# Revisamos nuevamente la cantidad de valores nulos en cada columna para asegurarnos de que se han eliminado
print(styles_df_clean.isnull().sum())
```


```{python}
styles_df_clean
```

### La base de datos final queda con 35844


```{python}
fig = px.bar(styles_df_clean.groupby('masterCategory').count().reset_index(), x='masterCategory',y='id',title='Count per Product Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})
```

## Analisis descriptivo


```{python}
fig = px.bar(styles_df_clean.groupby('masterCategory').count().reset_index(), x='masterCategory',y='id',title='Count per Product Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})
```

## Desarrollo del modelo

```{python}
styles_df_clean.columns
```

```{python}
styles_df_clean.drop(columns=['productDisplayName','file_found'],inplace=True)
```


```{python}
styles_df_clean.columns
```


```{python}
styles_df_clean = styles_df_clean.sample(frac=1).reset_index(drop=True)
n = len(styles_df_clean)
train = styles_df_clean.iloc[:int(n*0.8),:]
val = styles_df_clean.iloc[int(n*0.8):,:].reset_index(drop=True)
```

```{python}
# Crear una muestra de 5000 filas para el conjunto de entrenamiento
train_sampled = train.sample(n=1000, random_state=42).reset_index(drop=True)

# Crear una muestra de 1000 filas para el conjunto de validación
val_sampled = val.sample(n=200, random_state=42).reset_index(drop=True)
```

```{python}
datagen = ImageDataGenerator(rescale=1/255.)

train_generator = datagen.flow_from_dataframe(dataframe=train_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])

val_generator = datagen.flow_from_dataframe(dataframe=val_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])
```
```{python}
train_generator
```

## Una muestra de imagen de entrenamiento
```{python}
# Obtener el primer lote de imágenes
images_batch = next(train_generator)
# Imprimir la forma del lote de imágenes
print(images_batch.shape)  # Debe ser (32, 256, 256, 3) si batch_size=32 y las imágenes son RGB
# Mostrar la primera imagen del lote
import matplotlib.pyplot as plt
plt.imshow(images_batch[0])
plt.title('Primera imagen del primer lote')
plt.show()
```

## Una muestra de imagen de entrenamiento

```{python}
# Obtener el primer lote de imágenes
images_batch = next(val_generator)
# Imprimir la forma del lote de imágenes
print(images_batch.shape)  # Debe ser (32, 256, 256, 3) si batch_size=32 y las imágenes son RGB
# Mostrar la primera imagen del lote
import matplotlib.pyplot as plt
plt.imshow(images_batch[0])
plt.title('Primera imagen del primer lote')
plt.show()
```


```{python}
base_model = VGG16(include_top=False,input_shape=(256,256,3))

model = Sequential()
for layer in base_model.layers:
    model.add(layer)
model.add(GlobalAveragePooling2D())
model.summary()
```
```{python}

train_features = model.predict(train_generator,verbose=1)
```


```{python}

val_features = model.predict(val_generator,verbose=1)
```

### Guardar los objetos


```{python}
import pickle

# Especificar la ruta para guardar los archivos
train_features_path = '../Modelos/train_features.pkl'
val_features_path = '../Modelos/val_features.pkl'

# Guardar train_features en un archivo .pkl
with open(train_features_path, 'wb') as f:
    pickle.dump(train_features, f)

# Guardar val_features en un archivo .pkl
with open(val_features_path, 'wb') as f:
    pickle.dump(val_features, f)
```

# Llamar los objetos cargados

```{python}
import pickle

# Especificar la ruta para cargar los archivos
train_features_path = '../Modelos/train_features.pkl'
val_features_path = '../Modelos/val_features.pkl'

# Cargar train_features desde el archivo .pkl
with open(train_features_path, 'rb') as f:
    train_features = pickle.load(f)

# Cargar val_features desde el archivo .pkl
with open(val_features_path, 'rb') as f:
    val_features = pickle.load(f)
```
```{python}
from sklearn.decomposition import PCA
```
```{python}
pca = PCA(2)
pca.fit(train_features)
train_pca = pca.transform(train_features)
```
```{python}
test_pca = pca.fit_transform(val_features)
```
```{python}
train_pca = pd.DataFrame(train_pca)
train = train.iloc[:,0:10]
train = train.merge(train_pca, how='left', left_index=True, right_index=True)
```
```{python}
fig = px.scatter(train, x=0, y=1, color="masterCategory", title='Main Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
fig = px.scatter(train, x=0, y=1, color="gender", title='Gender', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
fig = px.scatter(train, x=0, y=1, color="subCategory", title='Sub Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
pca = PCA()
pca.fit(train_features)
```
```{python}
train_pca = pca.transform(train_features)
variance_explained = np.cumsum(pca.explained_variance_ratio_)
pcs = range(1,len(variance_explained)+1)
```
```{python}
px.line(x = pcs, y = variance_explained, title = 'Principal Components Cumulative Explained Variance', height=600,  labels={
                     "x": "Principal Components",
                     "y": "Explained Variance"})
```

```{python}

# Especificar la ruta para guardar el modelo PCA
pca_model_path = '../Modelos/pca_model.pkl'

# Guardar el modelo PCA en un archivo .pkl
with open(pca_model_path, 'wb') as f:
    pickle.dump(pca, f)

# Cargar el modelo PCA desde el archivo .pkl
# with open(pca_model_path, 'rb') as f:
#     loaded_pca = pickle.load(f)
```
```{python}
val_pca = pca.fit_transform(val_features)#[:,:313]
val_pca = pd.DataFrame(val_pca)
```
```{python}
val_pca
```
```{python}
val_sampled
```
```{python}
val = val_sampled.iloc[:,0:10]
```
```{python}
val = val.merge(val_pca, how='left', left_index=True, right_index=True)
```
```{python}
val
```
```{python}
X = val.iloc[:,-200:]
y = val['id']
```
```{python}
y
```
```{python}
from sklearn.neighbors import KNeighborsClassifier
import pickle

# Suponiendo que X e y ya están definidos
# Especificar la ruta para guardar el modelo
knn_model_path = '../Modelos/knn_model.pkl'

# Entrenar el modelo KNN
neigh = KNeighborsClassifier(n_neighbors=6)
neigh.fit(X, y)

# Guardar el modelo KNN en un archivo .pkl
with open(knn_model_path, 'wb') as f:
    pickle.dump(neigh, f)
```
```{python}
# for _ in range(5):
#     i = random.randint(1,len(val))
#     img1 = read_img(val_sampled.loc[i,'filename'])
#     dist, index = neigh.kneighbors(X=X.iloc[i,:].values.reshape(1,-1))
#     plt.figure(figsize = (4 , 4))
#     plt.imshow(img1)
#     plt.title("Input Image")

#     plt.figure(figsize = (20 , 20))
#     for i in range(1,6):
#         plt.subplot(1 , 5, i)
#         plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)
#         image = read_img(val_sampled.loc[index[0][i],'filename'])
#         plt.imshow(image)
#         plt.title(f'Similar Product #{i}')
```

# Implementación del modelo


```{python}

# Función para leer y procesar una imagen
def read_img(image_path):
    image = load_img(image_path, target_size=(256, 256, 3))
    image = img_to_array(image)
    image = image / 255.0
    return image

# Función para recomendar productos similares
def recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5):
    # Leer y procesar la imagen de entrada proporcionada por el usuario
    img1 = read_img(input_image_path)

    # Extraer características visuales de la imagen de entrada utilizando el modelo preentrenado
    img_features = model.predict(np.expand_dims(img1, axis=0))

    # Aplicar PCA a las características de la imagen de entrada
    img_features_pca = pca.transform(img_features)

    # Encontrar las imágenes más similares en el dataset utilizando KNN
    dist, index = neigh.kneighbors(img_features_pca)

    # Visualizar la imagen de entrada
    plt.figure(figsize=(4, 4))
    plt.imshow(img1)
    plt.title("Input Image")
    plt.show()

    # Visualizar las imágenes más similares del dataset
    plt.figure(figsize=(20, 20))
    for i in range(1, num_recommendations + 1):
        plt.subplot(1, num_recommendations, i)
        plt.subplots_adjust(hspace=0.5, wspace=0.3)
        similar_image_path = val_sampled.loc[index[0][i-1], 'filename']
        similar_image = read_img(similar_image_path)
        plt.imshow(similar_image)
        plt.title(f'Similar Product #{i}')
    plt.show()

```


```{python}

# Ejemplo de uso de la función
input_image_path = '../Datos/extracted_files/pruebas/54055.jpg'

# Llamar a la función de recomendación
recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5)
```

