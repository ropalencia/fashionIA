---
title: "Recomendación de moda"
lang: es    
author:
  - name: Ronald Gabriel Palencia
    email: ropalencia@unal.edu.co
  - name: Junior Antonio Muños Henao
    email: jmunozhe@unal.edu.co
format:
  html:
    code-fold: true
    code-summary: "Show the code"
jupyter: python3
#echo: false
theme:
          light: flatly
          dark: darkly
toc: true
appendix-style: default
---

# Introducción 

En el contexto del comercio electrónico de moda, los consumidores enfrentan un desafío creciente conocido como la parálisis por análisis. Este fenómeno se caracteriza por la dificultad de tomar decisiones de compra debido a la sobreabundancia de opciones disponibles, lo que puede llevar a la indecisión y, en ocasiones, a la insatisfacción con el proceso de compra. La rapidez con la que evolucionan las tendencias de moda y la demanda de personalización intensifican aún más este problema, creando un entorno en el que los consumidores se sienten abrumados y ansiosos.

En el Trabajo 2, se abordó esta problemática en profundidad, destacando cómo la sobreabundancia de opciones y la volatilidad de las tendencias impactan negativamente en la experiencia de compra. Se presentó la solución propuesta: un sistema de recomendación de moda basado en deep learning, diseñado para simplificar la experiencia de compra al ofrecer sugerencias personalizadas y adaptativas a las tendencias actuales. Esta solución busca mitigar la parálisis por análisis al proporcionar recomendaciones que se alineen con las preferencias individuales y los valores de los consumidores, facilitando así una experiencia de compra más eficiente y satisfactoria.

El presente Trabajo se enfoca en desarrollar e implementar esta solución, profundizando en los aspectos técnicos, metodológicos y económicos necesarios para su realización. La introducción de este trabajo reiterará el problema identificado y explorará cómo la solución propuesta en el Trabajo 02 será aplicada y evaluada en el contexto del desarrollo del sistema de recomendación. Esto incluirá una revisión de las metodologías y estrategias empleadas para abordar la parálisis por análisis y cómo estas se integrarán para mejorar la experiencia del consumidor en el mercado de moda digital.

En particular, en este Trabajo se detalla la implementación técnica del sistema de recomendación, que incluye el desarrollo y entrenamiento de modelos de deep learning para procesar y analizar grandes volúmenes de datos de moda. Se utilizarán técnicas avanzadas de procesamiento de lenguaje natural (NLP) para extraer características relevantes de descripciones de productos y reseñas de usuarios. Además, se integrarán mecanismos de feedback en tiempo real para ajustar las recomendaciones en función de las interacciones del usuario, y se evaluará el rendimiento del sistema mediante métricas de precisión y relevancia. Este enfoque técnico busca optimizar la personalización de las recomendaciones y asegurar que el sistema pueda adaptarse a las preferencias cambiantes de los consumidores, proporcionando así una solución robusta y eficaz a la parálisis por análisis.


# Análisis de requisitos del sistema


```{python}
import pandas as pd

# Crear un DataFrame
data = {
    "Requisitos funcionales": ["El sistema debe ser capaz de analizar interacciones, preferencias y comportamientos de compra de los usuarios para ofrecer recomendaciones de moda personalizadas que reflejen su estilo y necesidades.", "El sistema debe filtrar entre miles de productos para presentar solo aquellos que se alineen con las preferencias y necesidades del usuario, mejorando la eficiencia en la experiencia de compra.","El sistema debe ofrecer una plataforma dinámica que permita a los usuarios descubrir nuevas tendencias, diseñadores emergentes y marcas éticas, enriqueciendo su experiencia de compra.","El sistema debe adaptarse continuamente a las tendencias de moda globales y a los cambios en el comportamiento de los usuarios, asegurando que las recomendaciones sean siempre relevantes."],
    "Requisitos no funcionales": ["El sistema debe ser capaz de recuperarse rápidamente de fallos y seguir operando con un mínimo de interrupciones.", "El sistema debe ser escalable para manejar un gran volumen de usuarios y datos, garantizando un rendimiento eficiente incluso durante picos de demanda.","El sistema debe estar disponible para los usuarios en todo momento, con un tiempo de inactividad mínimo, garantizando la fiabilidad del servicio.","El sistema debe proporcionar recomendaciones en el menor tiempo posible para asegurar una experiencia de usuario fluida."],
}
df = pd.DataFrame(data)

# Mostrar la tabla en Markdown
print(df.to_markdown(index=False))
```
# Diagrama de arquitectura

aqui porner una imagen con el digrama de bases de datos y explicar de donde viene la base datos y demas


# Evidencias de pruebas funcionales

## EDA and Visualization

```{python}
#| echo: true
import numpy as np
import pandas as pd
import os
import re
from sklearn.decomposition import PCA

import tensorflow as tf
from threading import Thread
import time
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
import pickle
import random
from tqdm import tqdm
import plotly.express as px
from plotly.offline import init_notebook_mode
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import Sequence, to_categorical
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer
from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201, Xception
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
init_notebook_mode(connected=True)
```




```{python}
styles_df = pd.read_csv("../Datos/styles.csv", on_bad_lines='skip')
styles_df['filename'] = styles_df['id'].astype(str) + '.jpg'

#Nota: primero cambiar images por pruebas y correr, luego volver a poner images y ahi si lee todas las direcciones, es raro al verdad

#Esto parece que no hace falta en qmd
image_files = os.listdir("../Datos/extracted_files/images")



def check_image_path(filename):
    path = os.path.join("../Datos/extracted_files/images", filename)
    return path if os.path.exists(path) else None

styles_df['filename'] = styles_df['filename'].apply(check_image_path)

# Filtrar filas donde la imagen no existe
styles_df = styles_df[styles_df['filename'].notnull()]
styles_df['file_found'] = styles_df['id'].apply(lambda x: f"{x}.jpg" in image_files)
styles_df = styles_df[styles_df['file_found']].reset_index(drop=True)
#styles_df.shape[0]

#styles_df.isnull().sum()
# Eliminamos las filas que contienen valores faltantes
styles_df_clean = styles_df.dropna()

# Revisamos nuevamente la cantidad de valores nulos en cada columna para asegurarnos de que se han eliminado
#print(styles_df_clean.isnull().sum())


styles_df_clean.drop(columns=['productDisplayName','file_found'],inplace=True)
```

### Procesamiento de los datos


Para llegar a la base de datos final, fue necesario realizar varios pasos clave. Comenzamos cargando un archivo CSV con datos sobre estilos, asegurándonos de omitir cualquier línea malformada. Luego, creamos una columna en el DataFrame que generaba los nombres de archivo de las imágenes asociadas a cada registro.

Posteriormente, verificamos que los archivos de imagen realmente existieran en el directorio correspondiente. Esto nos permitió filtrar el DataFrame, eliminando los registros sin imágenes disponibles. Finalmente, añadimos una columna para marcar explícitamente qué imágenes estaban presentes y filtramos nuevamente para quedarnos solo con los registros válidos.

Todo este proceso de preprocesamiento, que fue esencial para depurar la base de datos y asegurar que solo incluyera registros con imágenes válidas y disponibles, puede verse detalladamente en el script de Python que se encuentra en el repositorio.

A continuación se presenta una muesta de la base datos, la cual quedo con 35844 registros


```{python}
styles_df_clean.head(5)
```


### Analisis descriptivo

```{python}
fig = px.bar(styles_df_clean.groupby('masterCategory').count().reset_index(), x='masterCategory',y='id',title='Count per Product Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})
```

La gráfica muestra que la categoría Apparel es la más representada, con una cantidad significativamente mayor de productos que las demás. Accessories y Footwear también tienen una presencia considerable, aunque menor en comparación con Apparel. Las categorías Personal Care, Free Items, Sporting Goods, y Home tienen muy pocos productos. Esto indica una concentración de datos en unas pocas categorías clave. Las categorías menos representadas podrían ser un área de menor enfoque o interés en el conjunto de datos.




## Desarrollo del modelo




### Partición de los datos 

La partición de los datos se realizó de la siguiente manera: se tomó el 80% de los registros del DataFrame styles_df_clean para formar el conjunto de entrenamiento (train), mientras que el 20% restante se reservó para el conjunto de validación (val).


```{python}
styles_df_clean = styles_df_clean.sample(frac=1).reset_index(drop=True)
n = len(styles_df_clean)
train = styles_df_clean.iloc[:int(n*0.8),:]
val = styles_df_clean.iloc[int(n*0.8):,:].reset_index(drop=True)
```

**Train**


```{python}
train.head(5)
```

**Validación**


```{python}
val.head(5)
```


Para entrenar el modelo, se decidió trabajar con una muestra debido a limitaciones computacionales, ya que el equipo disponible no era lo suficientemente potente para manejar todo el conjunto de datos. Inicialmente, el modelo se entrenará utilizando 1,000 registros o imágenes, y se validará con 200. La idea es incrementar gradualmente el tamaño de esta muestra hasta determinar el máximo volumen de datos que se puede utilizar de manera efectiva antes de implementar el modelo en producción.

```{python}
# Crear una muestra de 5000 filas para el conjunto de entrenamiento
train_sampled = train.sample(n=1000, random_state=42).reset_index(drop=True)

# Crear una muestra de 1000 filas para el conjunto de validación
val_sampled = val.sample(n=200, random_state=42).reset_index(drop=True)
```


### Preparador del generador de imagenes 


En esta etapa del proceso, se utiliza ImageDataGenerator de la biblioteca Keras para generar y preprocesar imágenes a partir de los datos. Inicialmente, se normalizan los valores de los píxeles de las imágenes, ajustándolos a un rango de [0, 1], lo que ayuda a mejorar la estabilidad y el rendimiento del modelo durante su entrenamiento. Posteriormente, se configuran dos generadores de imágenes: uno para el conjunto de entrenamiento y otro para el de validación. Ambos generadores redimensionan las imágenes a un tamaño uniforme de 256x256 píxeles y las agrupan en lotes de 32. Estos generadores permiten procesar las imágenes de manera eficiente en tiempo real, evitando la necesidad de cargar todo el conjunto de datos en memoria, lo que facilita la gestión de grandes volúmenes de datos durante el entrenamiento y la validación del modelo. Todo este proceso se puede observar en detalle en el script disponible en el repositorio, https://github.com/ropalencia/fashionIA/tree/main/Trabajo%203/Backend


```{python}
datagen = ImageDataGenerator(rescale=1/255.)

train_generator = datagen.flow_from_dataframe(dataframe=train_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])

val_generator = datagen.flow_from_dataframe(dataframe=val_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])
```


```{python}
train_generator
```

### Imagenes de muestra de los datos 


```{python}
import matplotlib.pyplot as plt

# Obtener el primer lote de imágenes de entrenamiento y validación
train_images_batch = next(train_generator)
val_images_batch = next(val_generator)

# Crear un mosaico con las dos imágenes
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# Mostrar la primera imagen del lote de entrenamiento
axes[0].imshow(train_images_batch[0])
axes[0].set_title('Muestra de imagen de entrenamiento')

# Mostrar la primera imagen del lote de validación
axes[1].imshow(val_images_batch[0])
axes[1].set_title('Muestra de imagen de validación')

# Eliminar los ejes para una mejor visualización
for ax in axes:
    ax.axis('off')

# Mostrar el mosaico
plt.show()

```


### Configuración del Modelo Base y Arquitectura Final

En esta etapa del proyecto, se configura la arquitectura del modelo utilizando la red preentrenada VGG16, conocida por su eficacia en tareas de visión por computadora. Primero, se carga el modelo VGG16 excluyendo sus capas finales, ya que solo se necesitan las capas convolucionales que extraen características de las imágenes. Luego, se crea un modelo secuencial en el que se añaden todas las capas de VGG16. Para finalizar, se incorpora una capa de GlobalAveragePooling2D, que reduce la dimensionalidad de las características extraídas, preparando el modelo para la tarea específica que se va a abordar. Este proceso permite aprovechar el aprendizaje previo de VGG16 mientras se adapta a nuevas entradas. Toda esta configuración se puede revisar en detalle en el script disponible en el repositorio

```{python}
base_model = VGG16(include_top=False,input_shape=(256,256,3))

model = Sequential()
for layer in base_model.layers:
    model.add(layer)
model.add(GlobalAveragePooling2D())
model.summary()

```

### Extracción de Características de las Imágenes y guardado

En esta sección, el código está configurado para utilizar el modelo previamente definido para extraer características de las imágenes de los conjuntos de entrenamiento y validación. Las líneas comentadas (val_features y train_features) indican que se planea pasar las imágenes a través del modelo (model.predict) para obtener representaciones de las imágenes, es decir, las características extraídas por el modelo hasta la última capa añadida. Estas características son los valores de salida de la red después de haber procesado las imágenes, y pueden ser utilizadas para entrenar un clasificador final o para otras tareas de análisis. Este proceso permite aprovechar las capas convolucionales de VGG16 para generar descripciones compactas y significativas de cada imagen.


```{python}

#val_features = model.predict(val_generator,verbose=1)

#train_features = model.predict(train_generator,verbose=1)

#import pickle

# Especificar la ruta para guardar los archivos
#train_features_path = '../Modelos/train_features.pkl'
#val_features_path = '../Modelos/val_features.pkl'

# Guardar train_features en un archivo .pkl
#with open(train_features_path, 'wb') as f:
#    pickle.dump(train_features, f)

# Guardar val_features en un archivo .pkl
#with open(val_features_path, 'wb') as f:
#    pickle.dump(val_features, f)
```




### Llamar los objetos guardados


Se cargan los modelos para continuar con el proceso de entrenamiento del modelo.


```{python}
import pickle

# Especificar la ruta para cargar los archivos
train_features_path = '../Modelos/train_features.pkl'
val_features_path = '../Modelos/val_features.pkl'

# Cargar train_features desde el archivo .pkl
with open(train_features_path, 'rb') as f:
    train_features = pickle.load(f)

# Cargar val_features desde el archivo .pkl
with open(val_features_path, 'rb') as f:
    val_features = pickle.load(f)
```


### Reducción de dimensionalidad


* Las características extraídas utilizando la red VGG16 producen un vector de 512 características. Por lo tanto, si tenemos, por ejemplo, 10,000 productos, la matriz de nuestros datos tendrá unas dimensiones de 10,000 x 512. Veamos si podemos reducir la dimensión de esta matriz.

* Para que un método de reducción de dimensionalidad basado en proyecciones lineales funcione, debe haber una alta correlación entre las características. Sin embargo, visualizar una tabla de coeficientes de correlación para una matriz de dimensiones tan altas utilizaría muchos recursos.

* Por lo tanto, vamos a realizar un Análisis de Componentes Principales (PCA) y analizar la varianza explicada por los componentes principales para verificar si nuestro enfoque de proyección lineal es adecuado.

### Entrenamiento del modelo pca solo dos y mas dimensiones


En esta etapa del desarrollo, se aplica el Análisis de Componentes Principales (PCA) para reducir la dimensionalidad de las características extraídas a partir de las imágenes. Inicialmente, las características de 512 dimensiones obtenidas del modelo VGG16 se reducen a solo 2 dimensiones, lo que simplifica significativamente la representación de los datos. Esta reducción permite manejar el conjunto de datos de manera más eficiente, tanto en términos de almacenamiento como de procesamiento, sin perder gran parte de la información relevante. Después de reducir las dimensiones, las nuevas características se integran con las características originales del conjunto de datos de entrenamiento. Esta combinación ofrece al modelo final una representación más compacta y posiblemente más informativa, optimizando así el proceso de entrenamiento y mejorando el rendimiento general del modelo. 

```{python}
# Inicializar PCA para reducir las características a 2 dimensiones
pca = PCA(2)

# Ajustar PCA a las características de entrenamiento y luego transformar
pca.fit(train_features)
train_pca = pca.transform(train_features)

# Aplicar PCA al conjunto de validación y transformarlo
test_pca = pca.fit_transform(val_features)

# Convertir las características reducidas de entrenamiento a un DataFrame
train_pca = pd.DataFrame(train_pca)

# Seleccionar las primeras 10 columnas del conjunto de entrenamiento original
train = train.iloc[:,0:10]

# Combinar las características originales con las nuevas características reducidas por PCA
train = train.merge(train_pca, how='left', left_index=True, right_index=True)

```

**Analísis de las dimensiones**

```{python}
fig = px.scatter(train, x=0, y=1, color="masterCategory", title='Main Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```

El gráfico anterior dispersión de los datos proyectados en los dos primeros componentes principales tras aplicar PCA. Cada punto representa un producto y está coloreado según su categoría principal (masterCategory). El gráfico revela cómo se distribuyen las diferentes categorías en el espacio reducido de dos dimensiones. Aunque hay cierta superposición entre las categorías, se pueden observar algunas agrupaciones, lo que sugiere que las categorías comparten características similares, aunque no están completamente separadas. Esta visualización ayuda a entender la distribución de las características reducidas y la relación entre las diferentes categorías.




```{python}
fig = px.scatter(train, x=0, y=1, color="gender", title='Gender', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```


El gráfico anterior de dispersión de los datos proyectados en los dos primeros componentes principales tras aplicar PCA, similar al gráfico anterior. Sin embargo, en esta ocasión, los puntos están coloreados según el género (gender) al que pertenecen los productos. Se puede observar que, aunque hay agrupaciones, las categorías de género están bastante mezcladas en el espacio de los componentes principales. Esto sugiere que las características extraídas no separan claramente los productos según el género, indicando una alta similitud en las características visuales de los productos independientemente del género al que están dirigidos.

```{python}
fig = px.scatter(train, x=0, y=1, color="subCategory", title='Sub Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```



 En este caso, los puntos están coloreados según la subcategoría de los productos (subCategory). A diferencia de los gráficos anteriores, aquí se observa una mayor dispersión y diversidad en la distribución de las subcategorías a lo largo de los dos componentes principales. Sin embargo, algunas subcategorías pueden compartir características similares, lo que provoca que ciertos puntos de diferentes subcategorías se solapen en el espacio de los componentes principales. Esto indica que, aunque PCA ha reducido la dimensionalidad de los datos, no todas las subcategorías se distinguen claramente en este espacio reducido, sugiriendo que algunos productos dentro de diferentes subcategorías tienen características visuales similares.


**Conclusión**

Los 2 componentes principales muestran una separabilidad razonablemente buena en términos de las categorías principales de productos. Tal vez, al considerar más componentes principales, la separabilidad será más evidente.



**PCA para más dimensiones**



Saplica PCA a las características del conjunto de entrenamiento para analizar cuánta varianza explican los componentes principales. Tras ajustar y transformar los datos, se calcula la varianza explicada acumulada, que indica cuánta información se conserva al considerar un número creciente de componentes. Finalmente, se genera una gráfica que muestra cómo aumenta la varianza explicada a medida que se incluyen más componentes, ayudando a decidir cuántos son necesarios para retener la mayor parte de la información.







```{python}
pca = PCA()
pca.fit(train_features)

train_pca = pca.transform(train_features)
variance_explained = np.cumsum(pca.explained_variance_ratio_)
pcs = range(1,len(variance_explained)+1)
px.line(x = pcs, y = variance_explained, title = 'Principal Components Cumulative Explained Variance', height=600,  labels={
                     "x": "Principal Components",
                     "y": "Explained Variance"})
```



**Dimensiones Reducidas: 512 -> 200**

* Los primeros 200 componentes principales explican el 99% de la varianza en los datos. Reduciremos las 

* dimensiones de las características de las imágenes a 200.



**Guardamos el modelo de pca entrenado**


```{python}

# Especificar la ruta para guardar el modelo PCA
pca_model_path = '../Modelos/pca_model.pkl'

# Guardar el modelo PCA en un archivo .pkl
with open(pca_model_path, 'wb') as f:
    pickle.dump(pca, f)

# Cargar el modelo PCA desde el archivo .pkl
# with open(pca_model_path, 'rb') as f:
#     loaded_pca = pickle.load(f)
```


**Aplicación de la reducción de dimensionalidad**

se aplica PCA para reducir las características del conjunto de validación a las 200 dimensiones más importantes. Las características reducidas se convierten en un DataFrame y se combinan con las primeras 10 columnas del conjunto de datos original para conservar información adicional relevante. Luego, se seleccionan las últimas 200 columnas resultantes como características (X), y se toma la columna id como la variable objetivo (y). Este proceso prepara los datos de validación de manera eficiente para su uso en un modelo, manteniendo la información clave en un espacio de menor dimensión.


```{python}
val_pca = pca.fit_transform(val_features)[:,:200]
val_pca = pd.DataFrame(val_pca)
val = val_sampled.iloc[:,0:10]
val = val.merge(val_pca, how='left', left_index=True, right_index=True)
X = val.iloc[:,-200:]
y = val['id']
```

### Entrenamiento del Modelo de Clasificación K-Nearest Neighbors (KNN)

Hasta este punto, se han preprocesado las imágenes, reducido la dimensionalidad de las características mediante PCA, y preparado un conjunto de datos optimizado. Ahora, el siguiente paso lógico es entrenar un modelo que pueda aprender a clasificar los productos en las diferentes categorías objetivo, utilizando las características procesadas.

El modelo KNN es una opción sencilla y efectiva para este propósito porque funciona bien en espacios de características reducidos, como el que se ha obtenido tras aplicar PCA. KNN clasifica cada producto en función de la similitud con sus vecinos más cercanos en el espacio de características, lo que puede ser especialmente útil cuando las categorías no están claramente separadas en el espacio, como se observó en los gráficos de componentes principales.

Aplicar un algoritmo de clasificación en esta parte del proyecto es esencial para convertir las características numéricas en predicciones categóricas, que es el objetivo final del sistema de clasificación de productos. Este paso convierte todo el trabajo de procesamiento de datos y reducción de dimensionalidad en un modelo práctico que puede ser utilizado para clasificar nuevas imágenes de productos con precisión.


```{python}
from sklearn.neighbors import KNeighborsClassifier
import pickle

# Suponiendo que X e y ya están definidos
# Especificar la ruta para guardar el modelo
knn_model_path = '../Modelos/knn_model.pkl'

# Entrenar el modelo KNN
neigh = KNeighborsClassifier(n_neighbors=6)
neigh.fit(X, y)

# Guardar el modelo KNN en un archivo .pkl
with open(knn_model_path, 'wb') as f:
    pickle.dump(neigh, f)
```






### Implementación del modelo

En esta parte del proyecto, se implementa una función para recomendar productos similares a partir de una imagen de entrada proporcionada por el usuario. El proceso comienza leyendo y procesando la imagen de entrada, ajustándola al tamaño esperado y normalizándola. Luego, se extraen las características visuales de la imagen utilizando el modelo preentrenado (VGG16) y se aplican las mismas técnicas de reducción de dimensionalidad (PCA) que se usaron en las imágenes del dataset original.

A continuación, el modelo K-Nearest Neighbors (KNN) se utiliza para encontrar las imágenes más similares en el conjunto de datos, basándose en las características procesadas de la imagen de entrada. Finalmente, se visualiza la imagen proporcionada por el usuario junto con las imágenes de productos más similares encontradas en el dataset, proporcionando una recomendación visual y personalizada. Esta función es clave para implementar un sistema de recomendación que pueda sugerir productos similares a los que un usuario podría estar interesado, mejorando así la experiencia del usuario en aplicaciones de comercio electrónico o catálogos de productos.



```{python}

# Función para leer y procesar una imagen
def read_img(image_path):
    image = load_img(image_path, target_size=(256, 256, 3))
    image = img_to_array(image)
    image = image / 255.0
    return image

# Función para recomendar productos similares
def recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5):
    # Leer y procesar la imagen de entrada proporcionada por el usuario
    img1 = read_img(input_image_path)

    # Extraer características visuales de la imagen de entrada utilizando el modelo preentrenado
    img_features = model.predict(np.expand_dims(img1, axis=0))

    # Aplicar PCA a las características de la imagen de entrada
    img_features_pca = pca.transform(img_features)

    # Encontrar las imágenes más similares en el dataset utilizando KNN
    dist, index = neigh.kneighbors(img_features_pca)

    # Visualizar la imagen de entrada
    plt.figure(figsize=(4, 4))
    plt.imshow(img1)
    plt.title("Input Image")
    plt.show()

    # Visualizar las imágenes más similares del dataset
    plt.figure(figsize=(20, 20))
    for i in range(1, num_recommendations + 1):
        plt.subplot(1, num_recommendations, i)
        plt.subplots_adjust(hspace=0.5, wspace=0.3)
        similar_image_path = val_sampled.loc[index[0][i-1], 'filename']
        similar_image = read_img(similar_image_path)
        plt.imshow(similar_image)
        plt.title(f'Similar Product #{i}')
    plt.show()

```



### Ejemplo de recomendación 1


```{python}

# Ejemplo de uso de la función
input_image_path = '../Datos/extracted_files/pruebas/54055.jpg'

# Llamar a la función de recomendación
recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5)
```




### Ejemplo de recomendación 2


```{python}

# Ejemplo de uso de la función
input_image_path = '../Datos/extracted_files/pruebas/54018.jpg'

# Llamar a la función de recomendación
recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5)
```


### Ejemplo de recomendación 3


```{python}

# Ejemplo de uso de la función
input_image_path = '../Datos/extracted_files/pruebas/54002.jpg'

# Llamar a la función de recomendación
recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5)
```


## Conclusión 

Se puede notar el modelo se equivoca, esto se debe a que el modelo fue entrenado con una muestra muy pequeña por problemas computacionales, sin embargo se espera que al amumentar el tamaño de muestra aumente ese problema disminuya.