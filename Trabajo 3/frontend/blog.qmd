---
title: "Recomendación de moda"
lang: es    
author:
  - name: Ronald Gabriel Palencia
    email: ropalencia@unal.edu.co
  - name: Junior Antonio Muños Henao
    email: jmunozhe@unal.edu.co
format:
  html:
    code-fold: true
jupyter: python3
echo: false
theme:
          light: flatly
          dark: darkly
toc: true
appendix-style: default
---

# Introducción 

En el contexto del comercio electrónico de moda, los consumidores enfrentan un desafío creciente conocido como la parálisis por análisis. Este fenómeno se caracteriza por la dificultad de tomar decisiones de compra debido a la sobreabundancia de opciones disponibles, lo que puede llevar a la indecisión y, en ocasiones, a la insatisfacción con el proceso de compra. La rapidez con la que evolucionan las tendencias de moda y la demanda de personalización intensifican aún más este problema, creando un entorno en el que los consumidores se sienten abrumados y ansiosos.

En el Trabajo 2, se abordó esta problemática en profundidad, destacando cómo la sobreabundancia de opciones y la volatilidad de las tendencias impactan negativamente en la experiencia de compra. Se presentó la solución propuesta: un sistema de recomendación de moda basado en deep learning, diseñado para simplificar la experiencia de compra al ofrecer sugerencias personalizadas y adaptativas a las tendencias actuales. Esta solución busca mitigar la parálisis por análisis al proporcionar recomendaciones que se alineen con las preferencias individuales y los valores de los consumidores, facilitando así una experiencia de compra más eficiente y satisfactoria.

El presente Trabajo se enfoca en desarrollar e implementar esta solución, profundizando en los aspectos técnicos, metodológicos y económicos necesarios para su realización. La introducción de este trabajo reiterará el problema identificado y explorará cómo la solución propuesta en el Trabajo 02 será aplicada y evaluada en el contexto del desarrollo del sistema de recomendación. Esto incluirá una revisión de las metodologías y estrategias empleadas para abordar la parálisis por análisis y cómo estas se integrarán para mejorar la experiencia del consumidor en el mercado de moda digital.

En particular, en este Trabajo se detalla la implementación técnica del sistema de recomendación, que incluye el desarrollo y entrenamiento de modelos de deep learning para procesar y analizar grandes volúmenes de datos de moda. Se utilizarán técnicas avanzadas de procesamiento de lenguaje natural (NLP) para extraer características relevantes de descripciones de productos y reseñas de usuarios. Además, se integrarán mecanismos de feedback en tiempo real para ajustar las recomendaciones en función de las interacciones del usuario, y se evaluará el rendimiento del sistema mediante métricas de precisión y relevancia. Este enfoque técnico busca optimizar la personalización de las recomendaciones y asegurar que el sistema pueda adaptarse a las preferencias cambiantes de los consumidores, proporcionando así una solución robusta y eficaz a la parálisis por análisis.


# Análisis de requisitos del sistema


```{python}
import pandas as pd

# Crear un DataFrame
data = {
    "Requisitos funcionales": ["El sistema debe ser capaz de analizar interacciones, preferencias y comportamientos de compra de los usuarios para ofrecer recomendaciones de moda personalizadas que reflejen su estilo y necesidades.", "El sistema debe filtrar entre miles de productos para presentar solo aquellos que se alineen con las preferencias y necesidades del usuario, mejorando la eficiencia en la experiencia de compra.","El sistema debe ofrecer una plataforma dinámica que permita a los usuarios descubrir nuevas tendencias, diseñadores emergentes y marcas éticas, enriqueciendo su experiencia de compra.","El sistema debe adaptarse continuamente a las tendencias de moda globales y a los cambios en el comportamiento de los usuarios, asegurando que las recomendaciones sean siempre relevantes."],
    "Requisitos no funcionales": ["El sistema debe ser capaz de recuperarse rápidamente de fallos y seguir operando con un mínimo de interrupciones.", "El sistema debe ser escalable para manejar un gran volumen de usuarios y datos, garantizando un rendimiento eficiente incluso durante picos de demanda.","El sistema debe estar disponible para los usuarios en todo momento, con un tiempo de inactividad mínimo, garantizando la fiabilidad del servicio.","El sistema debe proporcionar recomendaciones en el menor tiempo posible para asegurar una experiencia de usuario fluida."],
}
df = pd.DataFrame(data)

# Mostrar la tabla en Markdown
print(df.to_markdown(index=False))
```
# Diagrama de arquitectura

aqui porner una imagen con el digrama de bases de datos y explicar de donde viene la base datos y demas


# Evidencias de pruebas funcionales

## EDA and Visualization

```{python}
import numpy as np
import pandas as pd
import os
import re

import tensorflow as tf
from threading import Thread
import time
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
import pickle
import random
from tqdm import tqdm
import plotly.express as px
from plotly.offline import init_notebook_mode
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import Sequence, to_categorical
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer
from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201, Xception
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
init_notebook_mode(connected=True)
```




```{python}
styles_df = pd.read_csv("../Datos/styles.csv", on_bad_lines='skip')
styles_df['filename'] = styles_df['id'].astype(str) + '.jpg'

#Nota: primero cambiar images por pruebas y correr, luego volver a poner images y ahi si lee todas las direcciones, es raro al verdad

#Esto parece que no hace falta en qmd
image_files = os.listdir("../Datos/extracted_files/images")



def check_image_path(filename):
    path = os.path.join("../Datos/extracted_files/images", filename)
    return path if os.path.exists(path) else None

styles_df['filename'] = styles_df['filename'].apply(check_image_path)

# Filtrar filas donde la imagen no existe
styles_df = styles_df[styles_df['filename'].notnull()]
styles_df['file_found'] = styles_df['id'].apply(lambda x: f"{x}.jpg" in image_files)
styles_df = styles_df[styles_df['file_found']].reset_index(drop=True)
#styles_df.shape[0]

#styles_df.isnull().sum()
# Eliminamos las filas que contienen valores faltantes
styles_df_clean = styles_df.dropna()

# Revisamos nuevamente la cantidad de valores nulos en cada columna para asegurarnos de que se han eliminado
#print(styles_df_clean.isnull().sum())


styles_df_clean.drop(columns=['productDisplayName','file_found'],inplace=True)
```

### Procesamiento de los datos


Para llegar a la base de datos final, fue necesario realizar varios pasos clave. Comenzamos cargando un archivo CSV con datos sobre estilos, asegurándonos de omitir cualquier línea malformada. Luego, creamos una columna en el DataFrame que generaba los nombres de archivo de las imágenes asociadas a cada registro.

Posteriormente, verificamos que los archivos de imagen realmente existieran en el directorio correspondiente. Esto nos permitió filtrar el DataFrame, eliminando los registros sin imágenes disponibles. Finalmente, añadimos una columna para marcar explícitamente qué imágenes estaban presentes y filtramos nuevamente para quedarnos solo con los registros válidos.

Todo este proceso de preprocesamiento, que fue esencial para depurar la base de datos y asegurar que solo incluyera registros con imágenes válidas y disponibles, puede verse detalladamente en el script de Python que se encuentra en el repositorio.

A continuación se presenta una muesta de la base datos, la cual quedo con 35844 registros


```{python}
styles_df_clean.head(5)
```


### Analisis descriptivo

```{python}
fig = px.bar(styles_df_clean.groupby('masterCategory').count().reset_index(), x='masterCategory',y='id',title='Count per Product Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})
```

La gráfica muestra que la categoría Apparel es la más representada, con una cantidad significativamente mayor de productos que las demás. Accessories y Footwear también tienen una presencia considerable, aunque menor en comparación con Apparel. Las categorías Personal Care, Free Items, Sporting Goods, y Home tienen muy pocos productos. Esto indica una concentración de datos en unas pocas categorías clave. Las categorías menos representadas podrían ser un área de menor enfoque o interés en el conjunto de datos.




## Desarrollo del modelo




### Partición de los datos 

La partición de los datos se realizó de la siguiente manera: se tomó el 80% de los registros del DataFrame styles_df_clean para formar el conjunto de entrenamiento (train), mientras que el 20% restante se reservó para el conjunto de validación (val).


```{python}
styles_df_clean = styles_df_clean.sample(frac=1).reset_index(drop=True)
n = len(styles_df_clean)
train = styles_df_clean.iloc[:int(n*0.8),:]
val = styles_df_clean.iloc[int(n*0.8):,:].reset_index(drop=True)
```

**Train**


```{python}
train.head(5)
```

**Validación**


```{python}
val.head(5)
```


Para entrenar el modelo, se decidió trabajar con una muestra debido a limitaciones computacionales, ya que el equipo disponible no era lo suficientemente potente para manejar todo el conjunto de datos. Inicialmente, el modelo se entrenará utilizando 1,000 registros o imágenes, y se validará con 200. La idea es incrementar gradualmente el tamaño de esta muestra hasta determinar el máximo volumen de datos que se puede utilizar de manera efectiva antes de implementar el modelo en producción.

```{python}
# Crear una muestra de 5000 filas para el conjunto de entrenamiento
train_sampled = train.sample(n=1000, random_state=42).reset_index(drop=True)

# Crear una muestra de 1000 filas para el conjunto de validación
val_sampled = val.sample(n=200, random_state=42).reset_index(drop=True)
```




```{python}
datagen = ImageDataGenerator(rescale=1/255.)

train_generator = datagen.flow_from_dataframe(dataframe=train_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])

val_generator = datagen.flow_from_dataframe(dataframe=val_sampled,
                                             target_size=(256,256),
                                             x_col='filename',
                                             class_mode=None,
                                             batch_size=32,
                                             shuffle=False,
                                             classes=['images'])
```


```{python}
train_generator
```

## Una muestra de imagen de entrenamiento
```{python}
# Obtener el primer lote de imágenes
images_batch = next(train_generator)
# Imprimir la forma del lote de imágenes
print(images_batch.shape)  # Debe ser (32, 256, 256, 3) si batch_size=32 y las imágenes son RGB
# Mostrar la primera imagen del lote
import matplotlib.pyplot as plt
plt.imshow(images_batch[0])
plt.title('Primera imagen del primer lote')
plt.show()
```

## Una muestra de imagen de entrenamiento

```{python}
# Obtener el primer lote de imágenes
images_batch = next(val_generator)
# Imprimir la forma del lote de imágenes
print(images_batch.shape)  # Debe ser (32, 256, 256, 3) si batch_size=32 y las imágenes son RGB
# Mostrar la primera imagen del lote
import matplotlib.pyplot as plt
plt.imshow(images_batch[0])
plt.title('Primera imagen del primer lote')
plt.show()
```


```{python}
base_model = VGG16(include_top=False,input_shape=(256,256,3))

model = Sequential()
for layer in base_model.layers:
    model.add(layer)
model.add(GlobalAveragePooling2D())
model.summary()
```
```{python}

train_features = model.predict(train_generator,verbose=1)
```


```{python}

val_features = model.predict(val_generator,verbose=1)
```

### Guardar los objetos


```{python}
import pickle

# Especificar la ruta para guardar los archivos
train_features_path = '../Modelos/train_features.pkl'
val_features_path = '../Modelos/val_features.pkl'

# Guardar train_features en un archivo .pkl
with open(train_features_path, 'wb') as f:
    pickle.dump(train_features, f)

# Guardar val_features en un archivo .pkl
with open(val_features_path, 'wb') as f:
    pickle.dump(val_features, f)
```

# Llamar los objetos cargados

```{python}
import pickle

# Especificar la ruta para cargar los archivos
train_features_path = '../Modelos/train_features.pkl'
val_features_path = '../Modelos/val_features.pkl'

# Cargar train_features desde el archivo .pkl
with open(train_features_path, 'rb') as f:
    train_features = pickle.load(f)

# Cargar val_features desde el archivo .pkl
with open(val_features_path, 'rb') as f:
    val_features = pickle.load(f)
```
```{python}
from sklearn.decomposition import PCA
```
```{python}
pca = PCA(2)
pca.fit(train_features)
train_pca = pca.transform(train_features)
```
```{python}
test_pca = pca.fit_transform(val_features)
```
```{python}
train_pca = pd.DataFrame(train_pca)
train = train.iloc[:,0:10]
train = train.merge(train_pca, how='left', left_index=True, right_index=True)
```
```{python}
fig = px.scatter(train, x=0, y=1, color="masterCategory", title='Main Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
fig = px.scatter(train, x=0, y=1, color="gender", title='Gender', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
fig = px.scatter(train, x=0, y=1, color="subCategory", title='Sub Category', height=600, labels={
                     "0": "Principal Component 1",
                     "1": "Principal Component 2"})
fig.show()
```
```{python}
pca = PCA()
pca.fit(train_features)
```
```{python}
train_pca = pca.transform(train_features)
variance_explained = np.cumsum(pca.explained_variance_ratio_)
pcs = range(1,len(variance_explained)+1)
```
```{python}
px.line(x = pcs, y = variance_explained, title = 'Principal Components Cumulative Explained Variance', height=600,  labels={
                     "x": "Principal Components",
                     "y": "Explained Variance"})
```

```{python}

# Especificar la ruta para guardar el modelo PCA
pca_model_path = '../Modelos/pca_model.pkl'

# Guardar el modelo PCA en un archivo .pkl
with open(pca_model_path, 'wb') as f:
    pickle.dump(pca, f)

# Cargar el modelo PCA desde el archivo .pkl
# with open(pca_model_path, 'rb') as f:
#     loaded_pca = pickle.load(f)
```
```{python}
val_pca = pca.fit_transform(val_features)#[:,:313]
val_pca = pd.DataFrame(val_pca)
```
```{python}
val_pca
```
```{python}
val_sampled
```
```{python}
val = val_sampled.iloc[:,0:10]
```
```{python}
val = val.merge(val_pca, how='left', left_index=True, right_index=True)
```
```{python}
val
```
```{python}
X = val.iloc[:,-200:]
y = val['id']
```
```{python}
y
```
```{python}
from sklearn.neighbors import KNeighborsClassifier
import pickle

# Suponiendo que X e y ya están definidos
# Especificar la ruta para guardar el modelo
knn_model_path = '../Modelos/knn_model.pkl'

# Entrenar el modelo KNN
neigh = KNeighborsClassifier(n_neighbors=6)
neigh.fit(X, y)

# Guardar el modelo KNN en un archivo .pkl
with open(knn_model_path, 'wb') as f:
    pickle.dump(neigh, f)
```
```{python}
# for _ in range(5):
#     i = random.randint(1,len(val))
#     img1 = read_img(val_sampled.loc[i,'filename'])
#     dist, index = neigh.kneighbors(X=X.iloc[i,:].values.reshape(1,-1))
#     plt.figure(figsize = (4 , 4))
#     plt.imshow(img1)
#     plt.title("Input Image")

#     plt.figure(figsize = (20 , 20))
#     for i in range(1,6):
#         plt.subplot(1 , 5, i)
#         plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)
#         image = read_img(val_sampled.loc[index[0][i],'filename'])
#         plt.imshow(image)
#         plt.title(f'Similar Product #{i}')
```

# Implementación del modelo


```{python}

# Función para leer y procesar una imagen
def read_img(image_path):
    image = load_img(image_path, target_size=(256, 256, 3))
    image = img_to_array(image)
    image = image / 255.0
    return image

# Función para recomendar productos similares
def recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5):
    # Leer y procesar la imagen de entrada proporcionada por el usuario
    img1 = read_img(input_image_path)

    # Extraer características visuales de la imagen de entrada utilizando el modelo preentrenado
    img_features = model.predict(np.expand_dims(img1, axis=0))

    # Aplicar PCA a las características de la imagen de entrada
    img_features_pca = pca.transform(img_features)

    # Encontrar las imágenes más similares en el dataset utilizando KNN
    dist, index = neigh.kneighbors(img_features_pca)

    # Visualizar la imagen de entrada
    plt.figure(figsize=(4, 4))
    plt.imshow(img1)
    plt.title("Input Image")
    plt.show()

    # Visualizar las imágenes más similares del dataset
    plt.figure(figsize=(20, 20))
    for i in range(1, num_recommendations + 1):
        plt.subplot(1, num_recommendations, i)
        plt.subplots_adjust(hspace=0.5, wspace=0.3)
        similar_image_path = val_sampled.loc[index[0][i-1], 'filename']
        similar_image = read_img(similar_image_path)
        plt.imshow(similar_image)
        plt.title(f'Similar Product #{i}')
    plt.show()

```


```{python}

# Ejemplo de uso de la función
input_image_path = '../Datos/extracted_files/pruebas/54055.jpg'

# Llamar a la función de recomendación
recommend_similar_products(input_image_path, model, pca, neigh, val_sampled, num_recommendations=5)
```

